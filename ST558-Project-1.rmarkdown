---
title: "ST558"
format: html
editor: visual
editor_options: 
  chunk_output_type: console
---



## Public Use Microdata Sample (PUMS) Census API Query

The Public Use Microdata Sample (PUMS) Census API is a freely available resource that anyone can access to acquire pseudo person-level data collected for the U.S census. In order to access this immense data set we will have to interact with the application program interface (API), which is a set of protocols and rules that allows applications to communicate with a database. In this case we are going to be using R in order to access the API, and to start we are going to need to load in some very useful packages. Please read the notes in the code chunk below to better understand why we are loading in these packages:



```{r}
library(tidycensus) #Package built to allow users to return Census Bureau API data as tibbles
library(httr) #Provides a list of easy to use statements like get() for APIs
library(jsonlite) #Package that provides a JSON parser and generator
library(dplyr) 
library(tibble) #Used to create tibbles and is a part of tidyverse
library(ggplot2) #Used for plotting
library(tidyr) #Used to make data "wide"
library(hms) #Converts 00:00 or 00:00:00 to a time variable
library(lubridate) 

```



The next step we need to take is to create a helper function to assist with the query process for APIs. This function will convert the raw content to character strings, parse the JSON data, and then convert the data into a tibble. If you read through you will see that additional code has been added on that will further assist with the processing of the data we receive from the query process. In brief this function will also convert the character strings we receive from the initial table into either factor, numeric, or time variables.



```{r}
# Helper function to process API response
process_api_response <- function(api_response) {
  # Check if the response was successful
  if (api_response$status_code != 200) {
    stop("Error: API request failed with status code ", api_response$status_code)
  }
  
  # Convert raw content to character string
  content_string <- rawToChar(api_response$content)
  
  # Parse JSON data
  parsed_data <- fromJSON(content_string)
  
  # First row contains column names, the rest is the data
  column_names <- parsed_data[1, ]
  data_rows <- parsed_data[-1, ]
  
  # Convert to tibble and set column names
  tibble_data <- as_tibble(data_rows)
  colnames(tibble_data) <- column_names
  
  #creating new variable in order to check if variables are numeric
  valid_numeric_vars <- c("AGEP", "GASP", "GRPIP", "JWAP", "JWDP", "JWMNP", "PWGTP")
   
  #Created loop to convert proper numeric variables to numeric
  for(var in colnames(tibble_data)){
    if(var %in% valid_numeric_vars){
      tibble_data[[var]] <- as.numeric(tibble_data[[var]])
    }
  }
  #New variable to check for categorical variables
  valid_categorical_vars <- c("FER", "HHL", "HISPEED", "JWTRNS", "SCH", "SCHL", "SEX")
  
  #Created loop to convert proper categorical variables to factor
  for(var in colnames(tibble_data)){
    if(var %in% valid_categorical_vars){
      tibble_data[[var]] <- as.factor(tibble_data[[var]])
    }
  }
  #Creating levels for each categorical variable
  if ("SEX" %in% colnames(tibble_data)) {
    tibble_data <- tibble_data |>
      mutate(
        SEX = factor(SEX, labels = SEX_levels))
  }
    if ("SCHL" %in% colnames(tibble_data)) {
    tibble_data <- tibble_data |>
      mutate(
        SCHL = factor(SCHL, labels = SCHL_levels))
  }
  if ("SCH" %in% colnames(tibble_data)) {
    tibble_data <- tibble_data |>
      mutate(
        SCH = factor(SCH, labels = SCH_levels))
  }
    if ("JWTRNS" %in% colnames(tibble_data)) {
    tibble_data <- tibble_data |>
      mutate(
        JWTRNS = factor(JWTRNS, labels = JWTRNS_levels))
    }
    if ("HISPEED" %in% colnames(tibble_data)) {
    tibble_data <- tibble_data |>
      mutate(
        HISPEED = factor(HISPEED, labels = HISPEED_levels))
    }
    if ("HHL" %in% colnames(tibble_data)) {
    tibble_data <- tibble_data |>
      mutate(
         HHL = factor(HHL, labels =  HHL_levels))
    }
    if ("FER" %in% colnames(tibble_data)) {
    tibble_data <- tibble_data |>
      mutate(
         FER = factor(FER, labels = FER_levels))
  }
  #Pasting correct time values in for JWAP
  if("JWAP" %in% colnames(tibble_data)) {
  tibble_data <- tibble_data |>
   left_join(JWAP_intervals, join_by(JWAP)) |>
    rename(work_arrival_time = middle_time,
           arrival_meridiem = meridiem) |>
    select(-JWAP)
  } 
  
  #Pasting correct time values in for JWDP
   if("JWDP" %in% colnames(tibble_data)) {
  tibble_data <- tibble_data |>
   left_join(JWDP_intervals, join_by(JWDP)) |>
    rename(work_departure_time = middle_time2,
           departure_meridiem = meridiem2) |>
    select(-JWDP)
  } 
  
  return(tibble_data)
}

```



The next step is to create a year validation function in order to confirm only the correct years (2022 to 2010) are queried by the user. This function alongside other subsequent ones will be added to the main API query that we will be writing earlier, that way we can insure a user only selects variables that will work with our API query.



```{r}
# Function to validate the year
validate_year <- function(year) {
  cat("API year is :", year)
  if (year < 2010 || year > 2022) {
    stop("Invalid year. Year must be between 2010 and 2022.")
  }
}
```



After we create our year validation function we make another function that insures our user will only select the valid numeric and categorical variables our query will work with, and if the user does not select these variables they will get an error message letting them know what variables they can use instead. Additionally, the function insures that the PWGTP variable is always included with our query, as that variable is a representation of the number of people each row actually represents  



```{r}
# Function to validate numeric variables
process_numeric_vars <- function(numeric_vars = c("AGEP", "PWGTP")) {
  valid_numeric_vars <- c("AGEP", "GASP", "GRPIP", "JWAP", "JWDP", "JWMNP", "PWGTP")
  
  # Check PWGTP is always included
  if (!"PWGTP" %in% numeric_vars) {
    numeric_vars <- c(numeric_vars, "PWGTP")
  }
  
  # Validate numeric variables
  if (!all(numeric_vars %in% valid_numeric_vars)) {
    stop("Invalid numeric variables. Valid options: AGEP, GASP, GRPIP, JWAP, JWDP, JWMNP, PWGTP.")
  }
  
  # Check at least one numeric variable other than PWGTP
  if (!any(numeric_vars %in% valid_numeric_vars[valid_numeric_vars != "PWGTP"])) {
    stop("At least one numeric variable other than PWGTP must be returned.")
  } 
} 

# Function to validate categorical variables
process_categorical_vars <- function(categorical_vars = c("SEX")) {
  valid_categorical_vars <- c("FER", "HHL", "HISPEED", "JWTRNS", "SCH", "SCHL", "SEX")
  
  # Validate categorical variables
  if (!all(categorical_vars %in% valid_categorical_vars)) {
    stop("Invalid categorical variables. Valid options: FER, HHL, HISPEED, JWAP, JWDP, JWTRNS, SCH, SCHL, SEX.")
  }
  return(categorical_vars)
}
```


```

Looking ahead when we pull the time variables JWAP and JWDP out of the API they apppear as character strings that represent a time interval for the period in which a person generally begins work, such as 09:00 a.m to 09:04 a.m. This proves a problem for us as we we can not present the interval in a neat easily understandable manner for the user, so to make things more consistent and readable we will have the time variables return as the middle time between the interval. TO do this is quite a complicated tasks, and will require the usage of the readr which will allow us to seperate the character strings into useable columns. Due to the complexity of this we are going to extract the exact data for the whole variable in the API, then use separate_wider_delim to create two columns that represent the start and end of the time variable. Since the time variables are represented in the character strings as "00:00" we can use the parse_hm() function to have the columns for the start and end of the intervals represented in HH:MM:SS format, once they are in that format the start and end columsn can be subtracted then divided by two and added to the start to get the middle of the interval for each observation. In order to aid readability the time variables are going to be renamed to work_arrival_time or work_departure_time, in addition the proper am or pm designation columns (meridiem) will appear next to the variables. That way the user will still be able to mainipulate the variables as a time varaible and know if the variable is for the morning or night.

```{r}
# Function to process time variables
process_time_variable <- function(variable_name) {
 
   # Grabbing information from API
  temp <- httr::GET(paste0("https://api.census.gov/data/2022/acs/acs1/pums/variables/", variable_name, ".json"))
  temp_list <- temp$content |> rawToChar() |> jsonlite::fromJSON()
  
  # Getting just the variable names and their values
  time_values <- temp_list$values$item
  time_vals_sorted <- time_values[sort(names(time_values))]
  
  # Converting the values into a tibble
  time_tibble <- tibble(id = seq(0, length(time_vals_sorted) - 1), value = time_vals_sorted)
  
  # Converting to wide format
  time_wide <- separate_wider_delim(time_tibble, 
                                     cols = c("value"), 
                                     delim = " ", 
                                     names = c("start", "meridiem", "to", "end", "meridiem_2"), 
                                     too_few = "debug", 
                                     names_repair = "unique", 
                                     too_many = "drop") 
  
  # Select the needed rows and convert to usable format
  time_intervals <- time_wide |>
    select(id, start, meridiem, end, meridiem_2) |> #meridiem is to track if values were for am or pm
    mutate(start = parse_hm(start),
           end = parse_hm(end),
           variable_name = id)  
  
  # Make row 1 display NA across all columns for row 1    
  time_intervals[1, ] <- NA
  
  # Creating middle time value variable
  time_intervals <- time_intervals |>
    mutate(interval = (end - start) / 2,
           interval = as.numeric(interval),
           interval = as.period(interval))

  # Turning start into a period   
  time_intervals <- time_intervals |>
    mutate(start = as.period(start),
           middle_time = as.duration(start + interval)) |>
    select(middle_time, variable_name, meridiem) 
  
  # Turning the first row variable back to 0
  time_intervals[1, 2] <- 0
          
  # Converting back to a time variable        
  time_intervals <- time_intervals |>
    mutate(middle_time = hms::hms(seconds = middle_time))
  
  return(time_intervals)
} 

#Renaming variables to insure they work in the helper function
JWAP_intervals <- process_time_variable("JWAP")
JWAP_intervals <- JWAP_intervals |>
  rename(JWAP = variable_name)
         
JWDP_intervals <- process_time_variable("JWDP")
JWDP_intervals <- JWDP_intervals |>
  rename(JWDP = variable_name,
         middle_time2 = middle_time,
         meridiem2 = meridiem)

```

When we look at ahead we realize that if we pull in our categorical data we will not necessarily understand it as it is lacking the proper labels for the data contained, necesistating that we create proper level keys for the varaibles we will be querying. This will follow a similar process to how we got the time variables, but will be much simiplier 



```{r}
# Function to process time variables
process_cat_variable <- function(variable_name) {
 
   # Grabbing information from API
  temp <- httr::GET(paste0("https://api.census.gov/data/2022/acs/acs1/pums/variables/", variable_name, ".json"))
  temp_list <- temp$content |> rawToChar() |> jsonlite::fromJSON()
  
  # Getting just the variable names and their values
  cat_values <- temp_list$values$item
  cat_vals_sorted <- cat_values[sort(names(cat_values))]
  
  # Converting the values into a tibble
  cat_tibble <- tibble(id = seq(0, length(cat_vals_sorted) - 1), value = cat_vals_sorted)
  cat_vector <- cat_tibble$value
  
  return(cat_vector)
}

#Running function for categorical variables to store levels
SCHL_levels <- process_cat_variable("SCHL")
SEX_levels <- process_cat_variable("SEX")
SCH_levels <- process_cat_variable("SCH")
JWTRNS_levels <- process_cat_variable("JWTRNS")
HISPEED_levels <- process_cat_variable("HISPEED")
HHL_levels <- process_cat_variable("HHL")
FER_levels <- process_cat_variable("FER")
```





##Check that the value specified by the user is one of the above values

Main function to Query the API



```{r}
# 5. Main function: Query the API
query_census_pums <- function(
    year = 2022,
    numeric_vars = c("AGEP", "PWGTP"),
    categorical_vars = c("SEX"),
    geography_level = "All",
    geography_subset = NULL
) {
  # Validate the year
  validate_year(year)
  
  # Validate numeric variables
  process_numeric_vars(numeric_vars)
  
  # Validate categorical variables
  process_categorical_vars(categorical_vars)
  
  # Get API URL 
  base_url <- "https://api.census.gov/data"
  pathparam <- "acs/acs1/pums"  
  
  # Get the full URL
  url <- paste0(base_url, "/", year, "/", pathparam, "?get=", 
                paste(c(numeric_vars, categorical_vars), collapse = ",")) 
  
  # Check geography subset and add it to API call
  if (!is.null(geography_subset)) {
    url <- paste0(url, "&for=", geography_level, ":", geography_subset)
  }
  print(url)
  
  # API call using httr::GET
  api_response <- GET(url)
  
  # Check if the request was successful
  if (http_error(api_response)) {
    stop("API request failed: ", status_code(api_response))
  }
  
  # Process the response into a tibble
  data <- process_api_response(api_response)
  
  # Return the data 
  return(data)
}
print(url)
```



Testing Query with single year



```{r}
# Example for the single year 2022 with numeric and categorical variables
result <- query_census_pums(
  year = 2022, 
  numeric_vars = c("AGEP", "PWGTP", "GASP", "JWDP", "JWAP"),
  categorical_vars = c("SEX", "HISPEED", "FER"),
  geography_level = "state",
  geography_subset = "10"
)

# View the results
print ("end of function")
print(result)


```



Function for multiple years



```{r}
# 6. Function for multiple years
query_multiple_years <- function(
    years,                       
    numeric_vars = c("AGEP", "PWGTP"),  
    categorical_vars = c("SEX"),        
    geography_level = "All",            
    geography_subset = NULL             
) {
  all_years_data <- list()
  
  # Loop through each year
  for (year in years) {
    # Check if the year is valid
    #validate_year(year)
    cat("\nyear:", year)
    # Validate the year.    
    if (year < 2010 || year > 2022) {
      print(paste("Skipping invalid year:", year))
      next  # Skip this iteration and continue with the next year
    }
    
    # Get data for the current year using the single year function
    yearly_data <- query_census_pums(
      year = year,
      numeric_vars = numeric_vars,
      categorical_vars = categorical_vars,
      geography_level = geography_level,
      geography_subset = geography_subset
    )
    
    # Add a year column 
    yearly_data$year <- year
    
    # Store the current year data in the list
    all_years_data[[as.character(year)]] <- yearly_data
  }
  
  # Combine all the  data into one dataset
  final_data <- bind_rows(all_years_data) 
  
  #Adding census class to tibble
  class(final_data) <- c("census", class(final_data))
  
  # Return dataset
  return(final_data)
}
```



Testing the year 2022 to ensure query is working correctly

TEST



```{r}

# Example for the single year 2022 with numeric and categorical variables
result <- query_census_pums(
  year = 2022, 
  numeric_vars = c("JWAP", "GASP"),
  categorical_vars = c("SEX", "HISPEED"),
  geography_level = "state",
  geography_subset = "10"
)

# View the results
print ("end of function")
print(result)
```

```{r}
# Example of multiple years of data
multi_year_result <- query_multiple_years(
  years = c( 2016, 2017, 2018),    
  numeric_vars = c("AGEP", "PWGTP", "JWAP", "GRPIP" ),  
  categorical_vars = c("SEX", "HISPEED", "SCH", "FER"),  
  geography_level = "state",  
  geography_subset = "10"     
)



# View the result
print(multi_year_result)
```



Tibble processing



```{r}
# Define custom summary function for the 'census' class
summary.census <- function(census_data, 
                           numeric_vars = NULL, 
                           categorical_vars = NULL) {
  
  # Ensure PWGTP exists and is numeric
  if (!"PWGTP" %in% names(census_data)) {
    stop("Weight variable 'PWGTP' is missing from the dataset.")
  }
  
  # Separate numeric and categorical columns from the data
  if (is.null(numeric_vars)) {
    numeric_vars <- names(census_data)[sapply(census_data, is.numeric) & names(census_data) != "PWGTP"]
  }
  
  if (is.null(categorical_vars)) {
    categorical_vars <- names(census_data)[sapply(census_data, is.factor)]
  }
  # Weighted mean and standard deviation calculations
  summarize_numeric <- function(var_name, data) {
    numeric_vector <- as.numeric(data[[var_name]])
    weight_vector <- as.numeric(data[["PWGTP"]])
    
    # Check for missing values in the weight vector
    if (any(is.na(weight_vector))) {
      stop("Missing values found in the weight variable 'PWGTP'.")
    }
    
    # Calculate weighted mean
    weighted_mean <- sum(numeric_vector * weight_vector, na.rm = TRUE) / sum(weight_vector, na.rm = TRUE)
    
    # Calculate weighted standard deviation
    weighted_var <- sum(numeric_vector^2 * weight_vector, na.rm = TRUE) / sum(weight_vector, na.rm = TRUE)
    weighted_sd <- sqrt(weighted_var - weighted_mean^2)
    
    return(list(mean = weighted_mean, sd = weighted_sd))
  }
  
  # Initialize a list to store the summary results
  summary_list <- list()
  
  # Summarize numeric variables
  for (var in numeric_vars) {
    summary_list[[var]] <- summarize_numeric(var, census_data)
  }
  
  # Summarize categorical variables (counts)
  for (var in categorical_vars) {
    summary_list[[var]] <- table(census_data[[var]], useNA = "ifany")
  }
  
  return(summary_list)
}
```



TODO



```{r}
#Creating function for user to create weighted box plots
plot.census <- function(tibble_data, categorical_var, numeric_var) {
  
  #Telling user they must specify at least one categorical variable
  if (missing(categorical_var) || missing(numeric_var)){
    stop("Must include one categorical variable and one numeric variable")
  }
  #Telling user time variables can not be use as numeric variables
  if ("JWAP" %in% numeric_var){
    stop("JWAP is a time variable")
  }
   if ("JWDP" %in% numeric_var){
    stop("JWDP is a time variable")
  }
  
  p <- ggplot(tibble_data, 
              aes(x = get(categorical_var), y = get(numeric_var), weight = PWGTP)) + geom_boxplot() + 
                labs(title = paste("Box plot of", deparse(substitute(categorical_var)), "by", deparse(substitute(numeric_var))), x = categorical_var, y = numeric_var) + theme_light() 
  
  print(p)
}

#Plot example
plot.census(multi_year_result, "SEX", "AGEP")
```



## Census API Investigation

Now that we have created our functions and API Query we need to use it to analyze some data, and to do so we are going to look at

